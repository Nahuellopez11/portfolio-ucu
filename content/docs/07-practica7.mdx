---
title: Pr√°ctica 7
description: Desenmascarando sesgos algor√≠tmicos - An√°lisis √©tico con Fairlearn en datasets hist√≥ricos
---

# Pr√°ctica 7: Desenmascarando sesgos algor√≠tmicos: an√°lisis √©tico con Fairlearn en datasets hist√≥ricos


**Notebook completo:** [Pr√°ctica7.ipynb](#)

## Objetivos de Aprendizaje

- **DETECTAR** sesgo hist√≥rico en datasets reales (Boston Housing + Titanic)
- **ANALIZAR** impacto del sesgo en predicciones de modelos
- **COMPARAR** estrategias: detecci√≥n (regresi√≥n) vs correcci√≥n (clasificaci√≥n)
- **EVALUAR** cu√°ndo detectar vs cu√°ndo intentar corregir autom√°ticamente
- **DESARROLLAR** criterios √©ticos para deployment responsable

## Metodolog√≠a

### Parte I - Boston Housing: DETECTAR Sesgo Hist√≥rico

- Analizar sesgo oculto en variable B (proporci√≥n afroamericana)
- Cuantificar impacto del sesgo en predicciones (regresi√≥n)
- Analizar correlaciones y distribuciones por grupos raciales
- **No corregir** ‚Üí enfoque en detecci√≥n y an√°lisis cr√≠tico

### Parte II - Titanic: DETECTAR + CORREGIR Sesgo Sistem√°tico

- Detectar sesgo g√©nero/clase en protocolo "Women and Children First"
- Analizar interseccionalidad (g√©nero √ó clase social)
- Aplicar Fairlearn para correcci√≥n (clasificaci√≥n natural)

### Parte III - Ames Housing: Aplicaci√≥n Pr√°ctica

- An√°lisis de sesgo geogr√°fico y socioecon√≥mico
- Evaluaci√≥n de variables proxy problem√°ticas

## Resultados Principales

### Boston Housing Dataset

- **Brecha racial detectada:** -2.4% entre grupos de alta y baja proporci√≥n afroamericana
- **Correlaci√≥n variable B:** 0.333 con precios de vivienda
- **Decisi√≥n √©tica:** Uso exclusivamente educativo, no para producci√≥n
- **Justificaci√≥n:** Variable hist√≥ricamente sesgada, inapropiada para modelos de producci√≥n

### Titanic Dataset

- **Brecha de g√©nero:** 54.8% diferencia en supervivencia (mujeres vs hombres)
- **Brecha de clase:** 41.3% diferencia entre primera y tercera clase
- **Aplicaci√≥n Fairlearn:**
  - Performance loss: 6.2%
  - Mejora en Demographic Parity: 0.051
- **Recomendaci√≥n:** Evaluar caso por caso el trade-off precisi√≥n vs equidad

### Ames Housing Dataset

- **Brecha geogr√°fica:** 45% entre barrios m√°s y menos caros
- **Brecha temporal:** 28% diferencia entre casas nuevas vs antiguas
- **Riesgo:** Alto potencial de perpetuar desigualdades en contextos hipotecarios

## An√°lisis Profundo de Sesgo - Detecci√≥n Sin Correcci√≥n

### Visualizaci√≥n del Sesgo Racial en Boston Housing

La siguiente visualizaci√≥n muestra la distribuci√≥n de precios de vivienda agrupada por proporci√≥n de poblaci√≥n afroamericana, revelando patrones claros de sesgo hist√≥rico:

![An√°lisis de Sesgo por Grupos Raciales](/practica%207/bias-analysis-racial-groups.png)

### C√≥digo de An√°lisis

```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_boston

# Cargar dataset Boston Housing
boston = load_boston()
df = pd.DataFrame(boston.data, columns=boston.feature_names)
df['price'] = boston.target

# Crear grupos raciales basados en variable B (proporci√≥n afroamericana)
# B: proporci√≥n de poblaci√≥n afroamericana por √°rea censal
df['grupo_racial'] = pd.cut(df['B'], 
                           bins=[0, df['B'].median(), df['B'].max()], 
                           labels=['Baja_prop_afroam', 'Alta_prop_afroam'])

# Crear visualizaci√≥n comparativa
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

# Histograma de distribuci√≥n por grupo
df.groupby('grupo_racial')['price'].hist(alpha=0.7, ax=ax1, bins=20)
ax1.set_title('Distribuci√≥n de Precios por Grupo Racial')
ax1.set_xlabel('Precio (miles $)')
ax1.set_ylabel('Frecuencia')
ax1.legend(['Alta_prop_afroam', 'Baja_prop_afroam'])

# Boxplot comparativo
sns.boxplot(data=df, x='grupo_racial', y='price', ax=ax2)
ax2.set_title('Precios por Grupo Racial')
ax2.set_xlabel('Grupo Racial')
ax2.set_ylabel('Precio (miles $)')

plt.tight_layout()
plt.show()

# An√°lisis estad√≠stico del sesgo
print("=== AN√ÅLISIS DE SESGO RACIAL ===")
print(f"Precio promedio - Alta proporci√≥n afroam: ${df[df['grupo_racial']=='Alta_prop_afroam']['price'].mean():.1f}k")
print(f"Precio promedio - Baja proporci√≥n afroam: ${df[df['grupo_racial']=='Baja_prop_afroam']['price'].mean():.1f}k")

brecha = df[df['grupo_racial']=='Baja_prop_afroam']['price'].mean() - df[df['grupo_racial']=='Alta_prop_afroam']['price'].mean()
brecha_pct = (brecha / df[df['grupo_racial']=='Alta_prop_afroam']['price'].mean()) * 100

print(f"Brecha absoluta: ${brecha:.1f}k")
print(f"Brecha relativa: {brecha_pct:.1f}%")
print(f"Correlaci√≥n B-precio: {df['B'].corr(df['price']):.3f}")
```

### Interpretaci√≥n Cr√≠tica

#### üîç Hallazgos Clave:

- **Sesgo sistem√°tico:** Las √°reas con mayor proporci√≥n afroamericana muestran precios consistentemente menores
- **Distribuci√≥n sesgada:** El grupo de "alta proporci√≥n afroamericana" se concentra en el rango de precios bajos
- **Correlaci√≥n negativa:** Variable B muestra correlaci√≥n negativa con precios (-0.385)

#### ‚ö†Ô∏è Implicaciones √âticas:

- Este sesgo refleja discriminaci√≥n hist√≥rica en pol√≠ticas habitacionales
- La variable B act√∫a como proxy racial problem√°tico para predicciones
- No es apropiado intentar "corregir" este sesgo autom√°ticamente sin abordar las causas estructurales

#### üéØ Decisi√≥n de Detecci√≥n vs Correcci√≥n:

En este caso, **DETECTAR** es m√°s valioso que corregir porque:

- Visibiliza el problema hist√≥rico real
- Documenta la magnitud del sesgo para investigaci√≥n
- Evita perpetuar discriminaci√≥n en nuevos modelos
- Informa decisiones √©ticas sobre uso del dataset

## Framework √âtico Desarrollado

### Cu√°ndo DETECTAR √∫nicamente
- Sesgo hist√≥rico complejo (Boston racial bias)
- Contexto de aprendizaje/investigaci√≥n
- Variables proxy inevitables (neighborhood effects)

### Cu√°ndo DETECTAR + CORREGIR
- Sesgo sistem√°tico claro (Titanic gender bias)
- Contexto de producci√≥n con riesgo moderado
- Herramientas de fairness aplicables

### Cu√°ndo RECHAZAR el modelo
- Alto impacto socioecon√≥mico (lending, hiring)
- Sesgo severo no corregible
- Falta de transparencia en decisiones

## Insights T√©cnicos

- **Detecci√≥n vs Correcci√≥n:** Cada estrategia es apropiada para diferentes contextos
- **Sesgo hist√≥rico:** M√°s complejo de corregir que el sesgo sistem√°tico
- **Context matters:** El dominio determina la tolerancia al sesgo
- **Fairlearn limitations:** No todas las situaciones de sesgo son corregibles autom√°ticamente

## Herramientas Utilizadas

- **Fairlearn:** Biblioteca principal para detecci√≥n y correcci√≥n de sesgo
- **ExponentiatedGradient:** Algoritmo de correcci√≥n in-processing
- **DemographicParity:** Constraint de equidad demogr√°fica
- **MetricFrame:** An√°lisis de m√©tricas por grupos sensibles

## Reflexiones √âticas Cr√≠ticas

### ¬øCu√°ndo es m√°s valioso detectar que corregir autom√°ticamente?

Cuando el sesgo proviene de factores hist√≥ricos profundos. La correcci√≥n autom√°tica puede ocultar la ra√≠z del problema o generar resultados artificiales. La detecci√≥n permite visibilizar y documentar el sesgo sin introducir ruido.

### ¬øC√≥mo balancear transparencia vs utilidad?

La transparencia debe priorizarse frente a la utilidad. Un modelo con sesgo conocido y documentado es preferible a uno "ajustado" pero opaco, ya que los usuarios pueden comprender sus limitaciones.

### ¬øQu√© responsabilidades tenemos con sesgos hist√≥ricos no corregibles?

Debemos identificarlos, explicarlos y advertir sobre sus implicancias. Si no se pueden eliminar, corresponde evitar su uso en contextos sensibles. La responsabilidad del data scientist es tambi√©n social, no solo t√©cnica.

## Extensiones y Pr√≥ximos Pasos

### Algoritmos Adicionales de Fairness
- **GridSearch:** B√∫squeda exhaustiva de par√°metros justos
- **ThresholdOptimizer:** Post-processing para optimizar umbrales
- **CorrelationRemover:** Pre-processing para eliminar correlaciones

### Constraints Alternativos
- **EqualizedOdds:** Igualdad de oportunidades
- **TruePositiveRateParity:** Paridad en True Positive Rate
- **FalsePositiveRateParity:** Paridad en False Positive Rate

## Impacto y Aplicaciones

Esta pr√°ctica demuestra la importancia cr√≠tica de:

- **Auditor√≠a √©tica** en modelos de ML
- **Documentaci√≥n transparente** de limitaciones
- **Evaluaci√≥n contextual** de trade-offs
- **Responsabilidad social** en data science

El framework desarrollado es aplicable a cualquier dominio donde la equidad sea una consideraci√≥n importante, especialmente en sectores como finanzas, recursos humanos, justicia y salud.

## Recursos Interesantes

- **Fairlearn Documentation:** [fairlearn.org](https://fairlearn.org)

## Datasets Utilizados

### Boston Housing Dataset:
- Disponible en scikit-learn: `sklearn.datasets.load_boston()`
- Alternativa: UCI ML Repository - Housing
- **‚ö†Ô∏è Warning √âTICO:** Dataset con sesgo racial hist√≥rico, uso solo educativo

### Titanic Dataset:
- Kaggle - Titanic Dataset
- Disponible en seaborn: `sns.load_dataset('titanic')`
- Archivo CSV directo: titanic.csv

### Ames Housing Dataset:
- Kaggle - House Prices Dataset
- OpenML - Ames Housing
- Repositorio original: Ames Housing Data