---
title: "Pr√°ctica 7"
date: 2025-09-13
order: 7
---

# Pr√°ctica 7: Desenmascarando sesgos algor√≠tmicos

- **Autores:** Joaqu√≠n Batista, Milagros Cancela, Valent√≠n Rodr√≠guez, Alexia Aurrecoechea, Nahuel L√≥pez (G1)
- **Fecha:** Septiembre 2025
- **Entorno:** Python + Fairlearn + Scikit-learn + Pandas
- **Datasets:** Boston Housing, Titanic, Ames Housing

## üéØ Objetivo

El prop√≥sito de esta pr√°ctica es realizar un **an√°lisis √©tico completo de sesgos algor√≠tmicos** en datasets hist√≥ricos utilizando Fairlearn. A trav√©s de casos reales, exploramos la detecci√≥n, an√°lisis y correcci√≥n de sesgos en modelos de machine learning.

- **DETECTAR** sesgo hist√≥rico en datasets reales (Boston Housing + Titanic)
- **ANALIZAR** impacto del sesgo en predicciones de modelos
- **COMPARAR** estrategias: detecci√≥n (regresi√≥n) vs correcci√≥n (clasificaci√≥n)
- **EVALUAR** cu√°ndo detectar vs cu√°ndo intentar corregir autom√°ticamente
- **DESARROLLAR** criterios √©ticos para deployment responsable

---

## üîç An√°lisis de Sesgo Racial en Boston Housing

### Visualizaci√≥n del Sesgo Hist√≥rico

La siguiente visualizaci√≥n muestra la distribuci√≥n de precios de vivienda agrupada por proporci√≥n de poblaci√≥n afroamericana, revelando patrones claros de sesgo hist√≥rico:

![An√°lisis de Sesgo por Grupos Raciales](/practica%207/bias-analysis-racial-groups.png)

### C√≥digo de An√°lisis

```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_boston

# Cargar dataset Boston Housing
boston = load_boston()
df = pd.DataFrame(boston.data, columns=boston.feature_names)
df['price'] = boston.target

# Crear grupos raciales basados en variable B (proporci√≥n afroamericana)
df['grupo_racial'] = pd.cut(df['B'], 
                           bins=[0, df['B'].median(), df['B'].max()], 
                           labels=['Baja_prop_afroam', 'Alta_prop_afroam'])

# An√°lisis estad√≠stico del sesgo
print("=== AN√ÅLISIS DE SESGO RACIAL ===")
print(f"Precio promedio - Alta proporci√≥n afroam: ${df[df['grupo_racial']=='Alta_prop_afroam']['price'].mean():.1f}k")
print(f"Precio promedio - Baja proporci√≥n afroam: ${df[df['grupo_racial']=='Baja_prop_afroam']['price'].mean():.1f}k")

brecha = df[df['grupo_racial']=='Baja_prop_afroam']['price'].mean() - df[df['grupo_racial']=='Alta_prop_afroam']['price'].mean()
brecha_pct = (brecha / df[df['grupo_racial']=='Alta_prop_afroam']['price'].mean()) * 100

print(f"Brecha absoluta: ${brecha:.1f}k")
print(f"Brecha relativa: {brecha_pct:.1f}%")
print(f"Correlaci√≥n B-precio: {df['B'].corr(df['price']):.3f}")
```

### Interpretaci√≥n Cr√≠tica

**üîç Hallazgos Clave:**
- **Sesgo sistem√°tico**: Las √°reas con mayor proporci√≥n afroamericana muestran precios consistentemente menores
- **Distribuci√≥n sesgada**: El grupo de "alta proporci√≥n afroamericana" se concentra en el rango de precios bajos
- **Correlaci√≥n negativa**: Variable B muestra correlaci√≥n negativa con precios (-0.385)

**‚ö†Ô∏è Implicaciones √âticas:**
- Este sesgo refleja discriminaci√≥n hist√≥rica en pol√≠ticas habitacionales
- La variable B act√∫a como proxy racial problem√°tico para predicciones
- No es apropiado intentar "corregir" este sesgo autom√°ticamente sin abordar las causas estructurales

---

## üö¢ An√°lisis de Sesgo en Titanic Dataset

### Detecci√≥n de Sesgo de G√©nero y Clase

**Brecha de g√©nero**: 54.8% diferencia en supervivencia (mujeres vs hombres)
**Brecha de clase**: 41.3% diferencia entre primera y tercera clase

### Aplicaci√≥n de Fairlearn para Correcci√≥n

**Resultados de la correcci√≥n:**
- **Performance loss**: 6.2%
- **Mejora en Demographic Parity**: 0.051
- **Recomendaci√≥n**: Evaluar caso por caso el trade-off precisi√≥n vs equidad

---

## üè† An√°lisis de Sesgo en Ames Housing

### Sesgos Geogr√°ficos y Socioecon√≥micos

**Brecha geogr√°fica**: 45% entre barrios m√°s y menos caros
**Brecha temporal**: 28% diferencia entre casas nuevas vs antiguas
**Riesgo**: Alto potencial de perpetuar desigualdades en contextos hipotecarios

---

## ‚öñÔ∏è Framework √âtico Desarrollado

### Cu√°ndo DETECTAR √∫nicamente
- Sesgo hist√≥rico complejo (Boston racial bias)
- Contexto de aprendizaje/investigaci√≥n
- Variables proxy inevitables (neighborhood effects)

### Cu√°ndo DETECTAR + CORREGIR
- Sesgo sistem√°tico claro (Titanic gender bias)
- Contexto de producci√≥n con riesgo moderado
- Herramientas de fairness aplicables

### Cu√°ndo RECHAZAR el modelo
- Alto impacto socioecon√≥mico (lending, hiring)
- Sesgo severo no corregible
- Falta de transparencia en decisiones

---

## üß† Insights T√©cnicos

### Detecci√≥n vs Correcci√≥n
- **Detecci√≥n**: Cada estrategia es apropiada para diferentes contextos
- **Sesgo hist√≥rico**: M√°s complejo de corregir que el sesgo sistem√°tico
- **Context matters**: El dominio determina la tolerancia al sesgo
- **Fairlearn limitations**: No todas las situaciones de sesgo son corregibles autom√°ticamente

### Herramientas Utilizadas
- **Fairlearn**: Biblioteca principal para detecci√≥n y correcci√≥n de sesgo
- **ExponentiatedGradient**: Algoritmo de correcci√≥n in-processing
- **DemographicParity**: Constraint de equidad demogr√°fica
- **MetricFrame**: An√°lisis de m√©tricas por grupos sensibles

---

## üí° Reflexiones √âticas Cr√≠ticas

### ¬øCu√°ndo es m√°s valioso detectar que corregir autom√°ticamente?

Cuando el sesgo proviene de factores hist√≥ricos profundos. La correcci√≥n autom√°tica puede ocultar la ra√≠z del problema o generar resultados artificiales. La detecci√≥n permite visibilizar y documentar el sesgo sin introducir ruido.

### ¬øC√≥mo balancear transparencia vs utilidad?

La transparencia debe priorizarse frente a la utilidad. Un modelo con sesgo conocido y documentado es preferible a uno "ajustado" pero opaco, ya que los usuarios pueden comprender sus limitaciones.

### ¬øQu√© responsabilidades tenemos con sesgos hist√≥ricos no corregibles?

Debemos identificarlos, explicarlos y advertir sobre sus implicancias. Si no se pueden eliminar, corresponde evitar su uso en contextos sensibles. La responsabilidad del data scientist es tambi√©n social, no solo t√©cnica.

---

## üöÄ Extensiones y Pr√≥ximos Pasos

### Algoritmos Adicionales de Fairness
- **GridSearch**: B√∫squeda exhaustiva de par√°metros justos
- **ThresholdOptimizer**: Post-processing para optimizar umbrales
- **CorrelationRemover**: Pre-processing para eliminar correlaciones

### Constraints Alternativos
- **EqualizedOdds**: Igualdad de oportunidades
- **TruePositiveRateParity**: Paridad en True Positive Rate
- **FalsePositiveRateParity**: Paridad en False Positive Rate

---

## üìà Impacto y Aplicaciones

Esta pr√°ctica demuestra la importancia cr√≠tica de:

- **Auditor√≠a √©tica** en modelos de ML
- **Documentaci√≥n transparente** de limitaciones
- **Evaluaci√≥n contextual** de trade-offs
- **Responsabilidad social** en data science

El framework desarrollado es aplicable a cualquier dominio donde la equidad sea una consideraci√≥n importante, especialmente en sectores como finanzas, recursos humanos, justicia y salud.

---

## üõ†Ô∏è Herramientas y Tecnolog√≠as

### Librer√≠as Utilizadas
- **Fairlearn**: Detecci√≥n y correcci√≥n de sesgo algor√≠tmico
- **scikit-learn**: Modelos base para an√°lisis de sesgo
- **pandas**: Manipulaci√≥n y an√°lisis de datos
- **matplotlib/seaborn**: Visualizaciones de sesgo
- **numpy**: Operaciones num√©ricas

### Datasets Utilizados
- **Boston Housing**: Sesgo racial hist√≥rico (uso educativo √∫nicamente)
- **Titanic**: Sesgo de g√©nero y clase social
- **Ames Housing**: Sesgo geogr√°fico y socioecon√≥mico

---

## üìö Conclusiones y Aprendizajes

### Hallazgos Principales

1. **Sesgo es ubicuo**: Presente en la mayor√≠a de datasets hist√≥ricos
2. **Contexto importa**: La correcci√≥n autom√°tica no siempre es apropiada
3. **Transparencia es clave**: Documentar sesgos es m√°s importante que ocultarlos
4. **Responsabilidad social**: Los data scientists tienen obligaciones √©ticas

### Lecciones Aprendidas

- **Detecci√≥n primero**: Siempre identificar sesgos antes de intentar corregirlos
- **M√∫ltiples perspectivas**: Considerar diferentes grupos afectados
- **Trade-offs reales**: Equidad vs precisi√≥n requiere decisiones conscientes
- **Documentaci√≥n exhaustiva**: Registrar todas las decisiones √©ticas

---

## üîó Recursos y Referencias

- **Fairlearn Documentation**: [fairlearn.org](https://fairlearn.org/)
- **Boston Housing Dataset**: [UCI ML Repository](https://archive.ics.uci.edu/ml/datasets/Housing)
- **Titanic Dataset**: [Kaggle Titanic](https://www.kaggle.com/c/titanic)
- **√âtica en ML**: [ACM Code of Ethics](https://www.acm.org/code-of-ethics)