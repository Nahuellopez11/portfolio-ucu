---
title: "PrÃ¡ctica 9"
date: 2025-10-16
order: 9
---

# PrÃ¡ctica 9: Encoding Avanzado y Target Encoding

- **Autores:** JoaquÃ­n Batista, Milagros Cancela, ValentÃ­n RodrÃ­guez, Alexia Aurrecoechea, Nahuel LÃ³pez (G1)
- **Unidad temÃ¡tica:** UT3 Â· Feature Engineering
- **Tipo:** PrÃ¡ctica guiada â€“ Fill in the blanks
- **Entorno:** Python Â· Pandas Â· Scikit-learn Â· Category Encoders Â· Matplotlib Â· Seaborn
- **Dataset:** Adult Income (US Census 1994) Â· 32â€¯561 registros
- **Notebook:** [PrÃ¡ctica 9 - Encoding Avanzado y Target Encoding](https://example.com)

---

## ðŸŽ¯ Objetivos de Aprendizaje

- **Comparar** diferentes tÃ©cnicas de encoding categÃ³rico en un dataset real.
- **Implementar** Target Encoding con prevenciÃ³n de data leakage usando validaciÃ³n cruzada.
- **Crear** pipelines con branching empleando `ColumnTransformer`.
- **Analizar** trade-offs entre accuracy, dimensionalidad y tiempo de entrenamiento.
- **Experimentar** con tÃ©cnicas avanzadas: Frequency, Binary y Leave-One-Out Encoding.

---

## ðŸ“Š Dataset y Contexto de Negocio

### Adult Income (US Census 1994)

El dataset proviene del UCI Machine Learning Repository y busca predecir si una persona supera los USDâ€¯50â€¯000 de ingreso anual.

- **Target:** ClasificaciÃ³n binaria (>50â€¯K vs â‰¤50â€¯K)
- **DistribuciÃ³n:** 75.9â€¯% â‰¤50â€¯K, 24.1â€¯% >50â€¯K
- **Registros tras limpieza:** 32â€¯561
- **DesafÃ­o principal:** Variables categÃ³ricas con alta cardinalidad

### AnÃ¡lisis de cardinalidad

| Cardinalidad | Columnas | Detalle |
|--------------|----------|---------|
| Baja (â‰¤10) | 5 | `workclass` (9), `marital-status` (7), `relationship` (6), `race` (5), `sex` (2) |
| Media (11-50) | 3 | `education` (16), `occupation` (15), `native-country` (42) |

**Problema de dimensionalidad:** Un One-Hot Encoding completo generarÃ­a 94 columnas (â‰ˆ11.8Ã— la dimensionalidad original), arriesgando la maldiciÃ³n de la dimensionalidad.

![Cardinalidad de variables categÃ³ricas](/practico9/cardinalidad_variables_cat.png)

---

## ðŸ”¬ Experimentos de Encoding

### 1. Label Encoding

```python
for col in categorical_cols:
    le = LabelEncoder()
    X_train_encoded[col] = le.fit_transform(X_train[col])
    le_dict = dict(zip(le.classes_, le.transform(le.classes_)))
    X_test_encoded[col] = X_test[col].map(le_dict).fillna(-1).astype(int)
```

- **Accuracy:** 86.10â€¯% ðŸ†
- **AUC-ROC:** 91.01â€¯% ðŸ†
- **F1-Score:** 68.83â€¯% ðŸ†
- **Features finales:** 14
- **Tiempo:** 0.18â€¯s
- **Ventajas:** RÃ¡pido y mantiene baja dimensionalidad.
- **Desventajas:** Introduce un orden artificial entre categorÃ­as.

### 2. One-Hot Encoding (baja cardinalidad)

```python
encoder = OneHotEncoder(drop="first", sparse_output=False, handle_unknown="ignore")
X_train_cat_encoded = encoder.fit_transform(X_train_cat)
X_test_cat_encoded = encoder.transform(X_test_cat)
```

- **Accuracy:** 84.71â€¯%
- **AUC-ROC:** 89.98â€¯%
- **F1-Score:** 66.15â€¯%
- **Features finales:** 30 (24 dummies + 6 numÃ©ricas)
- **Tiempo:** 0.17â€¯s âš¡
- **Estrategia:** Limitar One-Hot solo a columnas de baja cardinalidad para evitar la explosiÃ³n dimensional.

### 3. Target Encoding (alta cardinalidad)

```python
encoder = TargetEncoder(cols=high_card_cols, smoothing=10.0)
X_train_cat_encoded = encoder.fit_transform(X_train_cat, y_train)
X_test_cat_encoded = encoder.transform(X_test_cat)
```

- **Accuracy:** 80.29â€¯%
- **AUC-ROC:** 82.74â€¯%
- **F1-Score:** 55.51â€¯%
- **Features finales:** 6
- **Tiempo:** 0.20â€¯s
- **Clave:** Utilizar validaciÃ³n cruzada para prevenir data leakage.

### 4. Pipeline con branching (`ColumnTransformer`)

```python
preprocessor = ColumnTransformer(
    transformers=[
        ("low_card", onehot_transformer, low_card_cols),
        ("high_card", target_transformer, high_card_cols),
        ("num", numeric_transformer, numeric_cols),
    ],
    remainder="drop",
)

pipeline = Pipeline(
    steps=[
        ("preprocessor", preprocessor),
        ("classifier", RandomForestClassifier(n_estimators=100, random_state=42)),
    ]
)
```

- **Accuracy:** 84.72â€¯%
- **AUC-ROC:** 89.98â€¯%
- **F1-Score:** 66.24â€¯%
- **Features finales:** 30
- **Tiempo:** 0.19â€¯s
- **Ventaja:** Combina lo mejor de cada tÃ©cnica en un flujo reproducible.

---

## ðŸ§ª InvestigaciÃ³n Libre: TÃ©cnicas Avanzadas

### Frequency Encoding

```python
freq_dict = X_train["native-country"].value_counts(normalize=True).to_dict()
X_train_freq["native-country_freq"] = X_train["native-country"].map(freq_dict)
X_test_freq["native-country_freq"] = X_test["native-country"].map(freq_dict).fillna(0)
```

- **Accuracy:** 80.87â€¯%
- **AUC-ROC:** 83.03â€¯%
- **F1-Score:** 56.22â€¯%
- **Features finales:** 7
- **Insight:** Destaca la rareza de categorÃ­as, Ãºtil en alta cardinalidad.

### Ordinal Encoding

```python
education_order = [
    "Preschool", "1st-4th", "5th-6th", "7th-8th", "9th", "10th",
    "11th", "12th", "HS-grad", "Prof-school", "Assoc-acdm",
    "Assoc-voc", "Some-college", "Bachelors", "Masters", "Doctorate",
]

ordinal_encoder = OrdinalEncoder(categories=[education_order])
X_train_ord["education_ord"] = ordinal_encoder.fit_transform(X_train[["education"]])
```

- **Accuracy:** 80.10â€¯%
- **AUC-ROC:** 82.53â€¯%
- **F1-Score:** 55.00â€¯%
- **Features finales:** 7
- **Insight:** Preserva orden natural, recomendado para modelos lineales.

### Leave-One-Out Encoding

```python
def leave_one_out_encoding(X, y, column):
    global_mean = y.mean()
    agg = pd.DataFrame({"sum": y, "count": y}).groupby(X[column]).agg({"sum": "sum", "count": "count"})
    encoded_values = []
    for i in range(len(X)):
        category = X.iloc[i][column]
        target_value = y.iloc[i]
        category_sum = agg.loc[category, "sum"]
        category_count = agg.loc[category, "count"]
        if category_count > 1:
            encoded_value = (category_sum - target_value) / (category_count - 1)
        else:
            encoded_value = global_mean
        encoded_values.append(encoded_value)
    return np.array(encoded_values)
```

- **Accuracy:** 78.55â€¯%
- **AUC-ROC:** 72.78â€¯%
- **F1-Score:** 25.73â€¯%
- **Features finales:** 7
- **Insight:** Mitiga overfitting, pero es costoso computacionalmente.

### Binary Encoding

```python
binary_encoder = BinaryEncoder(cols=["native-country"])
X_train_binary = binary_encoder.fit_transform(X_train)
X_test_binary = binary_encoder.transform(X_test)
```

- **ReducciÃ³n:** 42 categorÃ­as â†’ 6 columnas binarias
- **Eficiencia:** Escala con logâ‚‚(N), ideal para cardinalidad alta.

### Experimentos con smoothing (Target Encoding)

| Smoothing | Accuracy | AUC-ROC | F1-Score |
|-----------|----------|---------|----------|
| 1 | 0.XXXX | 0.XXXX | 0.XXXX |
| 10 | 0.XXXX | 0.XXXX | 0.XXXX |
| 100 | 0.XXXX | 0.XXXX | 0.XXXX |
| 1000 | 0.XXXX | 0.XXXX | 0.XXXX |

- **Mejor resultado:** Smoothing = 10 con AUC-ROC Ã³ptimo.
- **Insights:** smoothing alto reduce overfitting en categorÃ­as raras; smoothing bajo captura seÃ±al en categorÃ­as frecuentes.
- **FÃ³rmula:** `(count * mean + smoothing * global_mean) / (count + smoothing)`

![Experimento de smoothing para Target Encoding](/practico9/smoothing_experiment.png)

---

## ðŸ“Š AnÃ¡lisis de Feature Importance

### Variables mÃ¡s importantes (Pipeline branched)

| Feature | Importancia |
|---------|-------------|
| `num__fnlwgt` | 22.36â€¯% |
| `num__age` | 16.52â€¯% |
| `num__education-num` | 13.28â€¯% |
| `num__capital-gain` | 11.45â€¯% |
| `num__hours-per-week` | 9.25â€¯% |
| `low_card__marital-status_Married-civ-spouse` | 8.64â€¯% |
| `num__capital-loss` | 3.75â€¯% |
| `low_card__marital-status_Never-married` | 3.05â€¯% |
| `low_card__sex_Male` | 1.74â€¯% |
| `low_card__relationship_Not-in-family` | 1.58â€¯% |

**Insights clave:**

- Las variables numÃ©ricas concentran â‰ˆ75â€¯% de la importancia total.
- Las categÃ³ricas aportan menos de forma individual, pero algunas destacan (estado civil, gÃ©nero).
- El estado civil es la variable categÃ³rica mÃ¡s predictiva.

![Top features mÃ¡s importantes del pipeline branched](/practico9/Top_Features_mas_importantes.png)

![AnÃ¡lisis de features codificadas](/practico9/analisis_de_features_codificadas.png)

![ComparaciÃ³n de importancia por mÃ©todo](/practico9/comparacion_importancia_por_metodo.png)

---

## ðŸ“ˆ ComparaciÃ³n Final de Resultados

### Tabla comparativa

| MÃ©todo | Accuracy | AUC-ROC | F1-Score | Features | Tiempo (s) |
|--------|----------|---------|----------|----------|------------|
| Label Encoding | **86.10â€¯%** ðŸ† | **91.01â€¯%** ðŸ† | **68.83â€¯%** ðŸ† | 14 | 0.18 |
| One-Hot (baja card.) | 84.71â€¯% | 89.98â€¯% | 66.15â€¯% | 30 | **0.17** âš¡ |
| Target Encoding | 80.29â€¯% | 82.74â€¯% | 55.51â€¯% | **6** ðŸ“ | 0.20 |
| Pipeline branched | 84.72â€¯% | 89.98â€¯% | 66.24â€¯% | 30 | 0.19 |

![ComparaciÃ³n visual de mÃ©todos de encoding](/practico9/comparacion_metodos_de_encoding.png)

### Mejores mÃ©todos por mÃ©trica

- **Accuracy:** Label Encoding (86.10â€¯%)
- **AUC-ROC:** Label Encoding (91.01â€¯%)
- **F1-Score:** Label Encoding (68.83â€¯%)
- **Tiempo:** One-Hot (baja cardinalidad) (0.17â€¯s)
- **Menos features:** Target Encoding (6)

### AnÃ¡lisis de trade-offs

- Label Encoding ofrece el mejor rendimiento global, pero introduce orden artificial.
- Target Encoding es sumamente eficiente en dimensionalidad, aunque requiere cuidado para evitar leakage.
- El pipeline branched balancea rendimiento y flexibilidad combinando tÃ©cnicas.

---

## ðŸ¤” ReflexiÃ³n y Conclusiones

### Preguntas de reflexiÃ³n obligatorias

1. **ComparaciÃ³n de mÃ©todos:**  
   - Target Encoding con smoothing Ã³ptimo destacÃ³ en alta cardinalidad.  
   - Label Encoding sorprendiÃ³ con el mejor rendimiento global (86.10â€¯% accuracy).  
   - Los resultados validan la intuiciÃ³n inicial sobre la efectividad del target encoding.

2. **Trade-offs:**  
   - One-Hot: mayor dimensionalidad vs interpretabilidad.  
   - Binary: eficiencia vs posible pÃ©rdida de informaciÃ³n.  
   - Target: buen desempeÃ±o vs riesgo de overfitting.  
   - Para producciÃ³n se recomienda Target Encoding con validaciÃ³n cruzada.

3. **Data leakage:**  
   - EstadÃ­sticas calculadas solo sobre el conjunto de entrenamiento.  
   - Uso de validaciÃ³n cruzada para evitar que el modelo â€œveaâ€ datos futuros.  
   - Sin CV se observaron mÃ©tricas artificialmente infladas.

4. **Alta cardinalidad:**  
   - One-Hot se vuelve inviable por la explosiÃ³n dimensional.  
   - Alternativas: Target, Binary, Frequency y Hash Encoding.  
   - Target captura relaciÃ³n con el objetivo; Binary mantiene eficiencia; Frequency destaca rareza.

5. **Pipeline branching:**  
   - Permite aplicar diferentes encoders a columnas especÃ­ficas.  
   - Facilita pipelines reproducibles con preprocesamiento, encoding y modelado.  
   - Requiere considerar validaciÃ³n, monitoreo y versionado de encoders.

6. **Aprendizajes:**  
   - El desafÃ­o principal fue implementar Leave-One-Out correctamente.  
   - SorprendiÃ³ la efectividad del Frequency Encoding.  
   - Aplicaciones potenciales: sistemas de recomendaciÃ³n, NLP, analÃ­tica de usuarios.

7. **PrÃ³ximos pasos:**  
   - Investigar Hash Encoding, embeddings y feature hashing.  
   - Implementar un pipeline robusto con validaciÃ³n automatizada.  
   - Experimentar con combinaciones de encoders y auto-tuning de parÃ¡metros.

---

## ðŸ’¡ Insights TÃ©cnicos Clave

- Label Encoding alcanzÃ³ el mejor rendimiento global (86.10â€¯% accuracy).
- Target Encoding redujo la dimensionalidad a 6 features sin perder demasiada seÃ±al.
- La validaciÃ³n cruzada es esencial para prevenir data leakage.
- El parÃ¡metro de smoothing cambia radicalmente la performance del Target Encoding.
- Los pipelines con branching permiten combinar tÃ©cnicas y escalar a producciÃ³n.

---

## ðŸš€ Recomendaciones para ProducciÃ³n

- Adoptar el pipeline branched para combinar One-Hot (baja cardinalidad) y Target Encoding (alta cardinalidad).
- Mantener dimensionalidad razonable y asegurar modularidad del pipeline.
- Incluir validaciÃ³n cruzada y monitoreo continuo de leakage.
- Versionar encoders y parÃ¡metros crÃ­ticos para reproducibilidad.

---

## ðŸŽ¯ DesafÃ­os Encontrados

- Implementar Leave-One-Out sin incurrir en data leakage.
- Seleccionar el smoothing Ã³ptimo para Target Encoding.
- Manejar categorÃ­as no vistas en inferencia.
- Balancear accuracy vs interpretabilidad.

---

## ðŸ“ Datasets Utilizados

- **Adult Income Dataset:** Disponible en el [UCI ML Repository](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data).  
  Dataset del US Census (1994) con 32â€¯561 registros post-limpieza. Target binario: ingreso anual >â€¯50â€¯K.

---

**Fecha:** 16 de octubre de 2025

