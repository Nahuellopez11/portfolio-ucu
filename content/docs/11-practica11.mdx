---
title: "Pr√°ctica 11"
date: 2025-10-30
order: 11
---

# Pr√°ctica 11: Temporal Feature Engineering

- **Autores:** Joaqu√≠n Batista, Milagros Cancela, Valent√≠n Rodr√≠guez, Alexia Aurrecoechea, Nahuel L√≥pez (G1)
- **Unidad tem√°tica:** UT3 ¬∑ Feature Engineering
- **Tipo:** Pr√°ctica guiada ‚Äì Assignment UT3-11
- **Entorno:** Python ¬∑ Pandas ¬∑ Scikit-learn ¬∑ Matplotlib ¬∑ Seaborn ¬∑ NumPy
- **Dataset:** Online Retail (Kaggle) ¬∑ 397‚ÄØ884 transacciones ¬∑ 4‚ÄØ338 usuarios ¬∑ 18‚ÄØ562 √≥rdenes
- **Fecha:** Octubre 2025
- **Notebook:** Pr√°ctica 11 - Temporal Feature Engineering
- **Tiempo estimado:** 120‚Äì150 minutos

---

## üéØ Objetivos de Aprendizaje

- **Implementar** lag features usando `groupby().shift()` para capturar valores hist√≥ricos sin leakage.
- **Aplicar** rolling y expanding windows para modelar tendencias a corto y largo plazo.
- **Calcular** m√©tricas RFM para entender el comportamiento de recompra.
- **Construir** agregaciones por ventanas temporales (7d, 30d, 90d) que midan actividad reciente.
- **Codificar** variables calend√°ricas con encoding c√≠clico (sin/cos).
- **Evaluar** modelos con validaci√≥n temporal (`TimeSeriesSplit`) previniendo leakage.
- **Comparar** desempe√±o con y sin temporal features.

---

## üìä Dataset y Contexto de Negocio

### Online Retail Dataset

- **Target:** `will_purchase_again` (1 si el cliente compra nuevamente).
- **Distribuci√≥n:** 85.8‚ÄØ% s√≠ ¬∑ 14.2‚ÄØ% no.
- **Per√≠odo:** 2010-12-01 a 2011-12-09 (373 d√≠as).
- **Promedio de √≥rdenes:** 4.27 por usuario (5.99 para recurrentes).

**Escenario:** una empresa de e-commerce necesita anticipar si un cliente realizar√° otra compra. El reto es capturar patrones temporales fieles a la causalidad y evitar usar informaci√≥n futura.

![Exploraci√≥n temporal de √≥rdenes y distribuciones]( /practico11/temporal-exploration-distributions.png )

---

## üî¨ Metodolog√≠as Implementadas

### 1. Preparaci√≥n y agregaci√≥n a nivel orden

```python
df = (
    df_raw.dropna(subset=["CustomerID"])
          .loc[~df_raw["InvoiceNo"].astype(str).str.startswith("C")]
)
df = df[(df["Quantity"] > 0) & (df["UnitPrice"] > 0)]
df["total_amount"] = df["Quantity"] * df["UnitPrice"]
df = df.sort_values(["user_id", "order_date"]).reset_index(drop=True)
```

- Se consolidaron transacciones al nivel `order_id`, generando `cart_size` y `order_total`.
- Se a√±adieron columnas b√°sicas: `order_number`, `days_since_prior_order`.

### 2. Lag features

```python
orders_df["days_since_prior_lag_1"] = (
    orders_df.groupby("user_id")["days_since_prior_order"].shift(1)
)
```

- `groupby().shift()` garantiza historial por usuario y elimina leakage.
- Se generaron lags de 1, 2 y 3 √≥rdenes previas.

### 3. Rolling y expanding windows

```python
orders_df["rolling_cart_mean_3"] = (
    orders_df.groupby("user_id")["cart_size"]
    .shift(1)  # excluye orden actual
    .rolling(window=3, min_periods=1)
    .mean()
    .reset_index(level=0, drop=True)
)
```

- Rolling (3 √≥rdenes) captura tendencias recientes.
- Expanding acumula desde la primera compra para entender el hist√≥rico.

![Comparaci√≥n rolling vs expanding](/practico11/temporal-rolling-vs-expanding.png)

### 4. RFM (Recency, Frequency, Monetary)

- `recency_days`, `frequency_total_orders`, `monetary_avg` y `monetary_total`.
- `monetary_avg` se calcul√≥ con acumulados expandibles para evitar divisiones por cero.

![Distribuci√≥n de m√©tricas RFM](/practico11/temporal-rfm-distributions.png)

### 5. Ventanas temporales (7d, 30d, 90d)

- Conteo y gasto en distintos horizontes (`orders_7d`, `spend_30d`, `orders_90d`, etc.).
- Permiten detectar activaci√≥n o dormancia de clientes.

![Comparaci√≥n de ventanas temporales](/practico11/temporal-time-windows-comparison.png)

### 6. Product diversity

- `unique_products`, `product_diversity_ratio` y m√©tricas derivadas.
- Capturan si el cliente explora o repite productos.

![Diversidad de productos](/practico11/temporal-product-diversity.png)

### 7. Calendar features y encoding c√≠clico

```python
orders_df["hour_sin"] = np.sin(2 * np.pi * orders_df["order_hour_of_day"] / 24)
orders_df["hour_cos"] = np.cos(2 * np.pi * orders_df["order_hour_of_day"] / 24)
```

- Variables binarias (`is_weekend`, `is_month_start`, `is_holiday`) y codificaci√≥n sin/cos para hora, d√≠a y mes.

![Calendar encoding c√≠clico](/practico11/temporal-calendar-cyclic-encoding.png)

### 8. Variables externas (indicadores econ√≥micos)

- `gdp_growth`, `unemployment_rate`, `consumer_confidence` agregadas por mes.
- Solo `ffill` para mantener causalidad.

![Indicadores econ√≥micos y correlaci√≥n]( /practico11/temporal-economic-indicators.png )

### 9. Validaci√≥n temporal y evaluaci√≥n de modelos

- Se utiliz√≥ `TimeSeriesSplit(n_splits=3)` verificando que `train_max < val_min`.
- Comparaci√≥n:
  - **Modelo base (sin temporal):** AUC 0.6625 ¬± 0.0254.
  - **Modelo con temporal:** AUC 0.7204 ¬± 0.0623.
- Mejora absoluta: **+0.0580 AUC (8.7‚ÄØ%)**.

![Comparaci√≥n de performance](/practico11/temporal-model-performance-comparison.png)

### 10. Feature importance

- Feature importance de un Gradient Boosting demostr√≥ que:
  - `product_diversity_ratio`, `recency_days`, `unique_products`, `spend_90d`, `days_since_prior_lag_3` son top 5.
  - Lag/Window features suman 28.8‚ÄØ% de importancia total.

![Importancia de features temporales](/practico11/temporal-feature-importance.png)

---

## üõ°Ô∏è Data Leakage Detection

Checklist aplicado:

- `groupby().shift(1)` en todas las agregaciones temporales.
- Sin `bfill`, solo `ffill`.
- `TimeSeriesSplit` garantizando orden cronol√≥gico.
- Verificaci√≥n de brecha razonable entre train y CV.
- Revisi√≥n manual de top features para descartar columnas filtradas.

Resultado: **no se detect√≥ leakage** en el pipeline.

---

## üéì Conclusiones e Insights

- Temporal features aportaron **+8.7‚ÄØ%** de mejora en AUC.
- Categor√≠as m√°s influyentes:
  - Lag/Window (28.8‚ÄØ%)
  - Diversity (17.1‚ÄØ%)
  - RFM (15.0‚ÄØ%)
- Los features de ventanas temporales permiten identificar cambios recientes.
- La diversidad de productos es un predictor clave de recompra.

### Reglas de oro anti-leakage

- `df.groupby("user")["feature"].shift(1)` antes de cualquier `rolling/expanding`.
- No usar `shift` global sin agrupar.
- Validar siempre con splits temporales.
- Documentar los pasos y versionar el pipeline.

---

## üîç Preguntas de Reflexi√≥n

1. **Ventanas temporales m√°s relevantes:** 30 d√≠as ofreci√≥ mejor balance se√±al/ruido frente a 7 (ruidoso) y 90 (diluido).  
2. **Variables econ√≥micas:** aportaron poco al ser simuladas y de baja resoluci√≥n temporal; su valor crecer√≠a con datos reales y m√°s frecuentes.  
3. **RFM m√°s predictivo:** `recency_days`, seguido de `frequency_total_orders`; `monetary` aporta pero con menor peso.  
4. **Se√±ales de leakage:** ninguna; el monitoreo de gaps, feature importance y revisiones manuales confirm√≥ integridad.  
5. **Deploy diario:** mantener feature store incremental, c√°lculos online de lags/ventanas, versionado de features/modelos, monitoreo continuo y estrategias para cold-start.

---

## üìö Referencias y Recursos

- Kaggle ‚Äì Online Retail Dataset.
- *Feature Engineering for Machine Learning* ‚Äì cap√≠tulo de temporal features.
- Documentaci√≥n de Pandas (operaciones temporales).
- Scikit-learn ‚Äì `TimeSeriesSplit`.
- Framework RFM para e-commerce.

---

## ‚úÖ Checklist de Implementaci√≥n

- Lag features sin leakage (`groupby()+shift`).
- Rolling/expanding con exclusi√≥n de la observaci√≥n actual.
- M√©tricas RFM completas.
- Ventanas temporales (7d/30d/90d).
- Product diversity y calendar features con encoding c√≠clico.
- Variables externas integradas con `ffill`.
- Validaci√≥n TimeSeriesSplit.
- Comparativa de modelos y an√°lisis de importancia.
- Auditor√≠a de leakage.
Uso pr√°ctico:

Rolling ‚Üí "¬øEl usuario est√° comprando m√°s frecuentemente √∫ltimamente?"
Expanding ‚Üí "¬øCu√°l es el comportamiento hist√≥rico promedio del usuario?"
Parte 4: RFM Analysis¬∂
4.1 Features RFM (Recency, Frequency, Monetary)¬∂
Distribuciones RFM

RFM es un framework cl√°sico de an√°lisis de comportamiento en e-commerce:

Recency: D√≠as desde la √∫ltima compra
Frequency: Total de √≥rdenes hist√≥ricas
Monetary: Gasto promedio y total hist√≥rico
# RECENCY
reference_date = orders_df['order_date'].max()
orders_df['recency_days'] = (reference_date - orders_df['order_date']).dt.days

# FREQUENCY
orders_df['frequency_total_orders'] = orders_df.groupby('user_id')['order_id'].transform('count')

# MONETARY
orders_df['monetary_avg'] = (
    orders_df['expanding_total_spent'] / 
    orders_df['total_orders_so_far'].replace(0, 1)
)
orders_df['monetary_total'] = orders_df['expanding_total_spent']
Estad√≠sticas RFM:

Recency promedio: 160 d√≠as
Frequency promedio: 18 √≥rdenes por usuario
Monetary promedio: $1.88M por usuario (acumulado hist√≥rico)
Correlaciones:

Recency vs Frequency: 0.021 (baja, son dimensiones independientes)
Frequency vs Monetary: -0.326 (usuarios m√°s frecuentes gastan menos por orden en promedio)
Parte 5: Time Window Aggregations¬∂
5.1 Ventanas Temporales (7d, 30d, 90d)¬∂
Comparaci√≥n de Time Windows

Concepto: Capturan comportamiento reciente vs mediano plazo. Cr√≠ticas para detectar cambios en actividad.

def calculate_time_windows_for_user(user_data):
    """Calcula ventanas temporales excluyendo la orden actual"""
    # Para cada orden, contar √≥rdenes y gasto en los √∫ltimos 7d, 30d, 90d
    # SOLO usando datos hist√≥ricos (excluir orden actual)
    ...
Features generadas:

orders_7d: √ìrdenes en √∫ltimos 7 d√≠as (excluyendo actual)
orders_30d: √ìrdenes en √∫ltimos 30 d√≠as
orders_90d: √ìrdenes en √∫ltimos 90 d√≠as
spend_7d, spend_30d, spend_90d: Gasto en cada ventana
Resultados:

7 d√≠as: Promedio 0.41 √≥rdenes, $294.55 gastado
30 d√≠as: Promedio 1.42 √≥rdenes, $922.79 gastado
90 d√≠as: Promedio 3.69 √≥rdenes, $2,392.72 gastado
Insight: Comparar ventanas detecta usuarios "activ√°ndose" (aumento en 7d vs 90d) o "durmiendo" (disminuci√≥n en actividad).

Parte 6: Product Diversity Features¬∂
6.1 M√©tricas de Diversidad¬∂
Product Diversity

Capturan qu√© tan variado es el comportamiento de compra de un usuario.

diversity_features = df.groupby('user_id').agg({
    'product_id': 'nunique',     # Productos √∫nicos comprados
    'Country': 'nunique'         # Pa√≠ses desde donde compra
}).reset_index()

diversity_features['product_diversity_ratio'] = (
    diversity_features['unique_products'] / diversity_features['total_items']
)
Interpretaci√≥n:

Ratio alto (~1.0): Usuario explora productos variados (alta diversidad, nunca recompra)
Ratio bajo (<0.5): Usuario recompra frecuentemente (baja diversidad, lealtad a productos)
Resultados:

Ratio promedio: 0.85 (usuarios tienden a explorar m√°s que recomprar)
Mediana: 0.91
Parte 7: Calendar Features y Encoding C√≠clico¬∂
7.1 Features de Calendario¬∂
Calendar Features - Encoding C√≠clico

Features binarias:

is_weekend: Orden en fin de semana
is_month_start: Orden en primeros 5 d√≠as del mes
is_month_end: Orden en √∫ltimos 5 d√≠as del mes
is_holiday: Orden en feriados UK (Navidad, A√±o Nuevo)
7.2 Encoding C√≠clico (sin/cos)¬∂
Problema: Variables como hora (0-23) o d√≠a de semana (0-6) tienen naturaleza c√≠clica:

La hora 23 est√° "cerca" de la hora 0
El domingo (6) est√° "cerca" del lunes (0)
Soluci√≥n: Usar transformaciones sin/cos para capturar continuidad circular.

# Hour of day (0-23)
orders_df['hour_sin'] = np.sin(2 * np.pi * orders_df['order_hour_of_day'] / 24)
orders_df['hour_cos'] = np.cos(2 * np.pi * orders_df['order_hour_of_day'] / 24)

# Day of week (0-6)
orders_df['dow_sin'] = np.sin(2 * np.pi * orders_df['order_dow'] / 7)
orders_df['dow_cos'] = np.cos(2 * np.pi * orders_df['order_dow'] / 7)

# Month (1-12)
orders_df['month_sin'] = np.sin(2 * np.pi * (orders_df['month'] - 1) / 12)
orders_df['month_cos'] = np.cos(2 * np.pi * (orders_df['month'] - 1) / 12)
Ventaja: En el espacio sin/cos, las 23h est√°n "cerca" de las 0h, y el domingo est√° "cerca" del lunes. El modelo captura mejor la continuidad temporal.

Efecto Weekend:

Cart size promedio en weekdays: ~21 items
Cart size promedio en weekends: ~24 items
Insight: Usuarios compran m√°s en fines de semana
Parte 8: External Variables (Economic Indicators)¬∂
8.1 Indicadores Econ√≥micos¬∂
Economic Indicators

Las variables externas proporcionan contexto macro que afecta el comportamiento del consumidor.

# Crear datos econ√≥micos mensuales simulados
economic_data = pd.DataFrame({
    'month_date': date_range_monthly,
    'gdp_growth': np.random.normal(2.5, 0.5, len(date_range_monthly)),
    'unemployment_rate': np.random.normal(4.0, 0.3, len(date_range_monthly)),
    'consumer_confidence': np.random.normal(100, 5, len(date_range_monthly))
})

# Merge con orders_df
orders_df = orders_df.merge(economic_data, on='month_period', how='left')

# ‚ö†Ô∏è CR√çTICO: Solo forward fill (ffill), NUNCA backward fill (bfill)
orders_df['gdp_growth'] = orders_df['gdp_growth'].ffill()
‚ö†Ô∏è Regla de oro:

Forward fill (ffill): Usar informaci√≥n pasada para rellenar presente/futuro ‚úÖ
Backward fill (bfill): Usar informaci√≥n futura para rellenar pasado ‚ùå DATA LEAKAGE!
Rangos:

GDP Growth: 2.27% a 3.29%
Unemployment Rate: 3.43% a 4.44%
Consumer Confidence: ~94 a ~102
Relaci√≥n con √≥rdenes: Correlaci√≥n moderada entre consumer confidence y n√∫mero de √≥rdenes mensuales.

Parte 9: Time-based Validation y Model Performance¬∂
9.1 TimeSeriesSplit Validation¬∂
‚ö†Ô∏è CR√çTICO: Para datos temporales, usar TimeSeriesSplit en lugar de KFold est√°ndar.

from sklearn.model_selection import TimeSeriesSplit

tscv = TimeSeriesSplit(n_splits=3)

for fold, (train_idx, val_idx) in enumerate(tscv.split(X), 1):
    # Train siempre antes de validation (temporalmente)
    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

    # Verificar que train_dates.max() < val_dates.min()
    assert train_dates.max() < val_dates.min()  # Previene data leakage
Resultados de Cross-Validation:

Fold	Train Size	Val Size	AUC
1	1,966	1,965	0.7450
2	3,931	1,965	0.7815
3	5,896	1,965	0.6348
Mean AUC: 0.7204 ¬± 0.0763

9.2 Comparaci√≥n: Con vs Sin Temporal Features¬∂
Model Performance Comparison

Modelos comparados:

Base Model (sin temporal features): Solo features b√°sicas
order_dow, order_hour_of_day, is_weekend, is_holiday, cart_size, order_total, order_number
AUC: 0.6625 ¬± 0.0254

Full Model (con temporal features): Todas las features temporales

Lag features, Rolling/Expanding, RFM, Time Windows, Diversity, Calendar, Economic
AUC: 0.7204 ¬± 0.0623
Impacto de Temporal Features:

Improvement: +0.0580 AUC (+8.7%)
Las temporal features mejoran significativamente el performance del modelo
Lag/Window features son cr√≠ticas para capturar patrones de comportamiento
Parte 10: Feature Importance Analysis¬∂
10.1 An√°lisis de Importancia¬∂
Feature Importance

Top 10 Features M√°s Importantes:

product_diversity_ratio (0.1047) - Diversity
recency_days (0.0785) - RFM
unique_products (0.0656) - Diversity
spend_90d (0.0523) - Time Window
days_since_prior_lag_3 (0.0472) - Lag/Window
days_since_prior_lag_1 (0.0433) - Lag/Window
order_total (0.0395) - Base
days_since_prior_lag_2 (0.0365) - Lag/Window
monetary_total (0.0362) - RFM
monetary_avg (0.0356) - RFM
Importancia por Categor√≠a:

Categor√≠a	Total Importance	Features
Lag/Window	0.2884	8 features
Diversity	0.1712	3 features
RFM	0.1502	3 features
Time Window	0.1351	6 features
Calendar	0.0998	11 features
Base	0.0899	3 features
Economic	0.0654	3 features
Insights clave:

Lag/Window features son las m√°s importantes (28.8% de importancia total)
Diversity es cr√≠tica para predecir recompra (17.1%)
RFM sigue siendo relevante (15.0%)
Time Windows capturan comportamiento reciente (13.5%)
Calendar/Economic aportan valor pero menor (9.98% + 6.54%)
Parte 11: Data Leakage Detection¬∂
11.1 Verificaciones Realizadas¬∂
Checklist anti-leakage:

‚úÖ Performance check: - Train accuracy: 0.8808 - CV AUC: 0.7204 - Gap razonable (~0.16), no hay overfitting sospechoso

‚úÖ Feature importance check: - Top 5 features no incluyen nombres sospechosos (target, label, leak) - Features son todas temporales y leg√≠timas

‚úÖ Temporal consistency: - TimeSeriesSplit usado en lugar de KFold - Validation siempre posterior a train (excepto fold 1 con timestamps exactamente iguales en el split) - Train dates < Validation dates

‚úÖ Feature calculation check: - Todas las aggregations usan .shift(1) - Solo forward fill (no backward fill) - Rolling windows calculadas correctamente

Conclusi√≥n: No se detect√≥ data leakage evidente. Las features temporales est√°n correctamente implementadas.

üéì Conclusiones y Lecciones Aprendidas¬∂
Hallazgos Principales¬∂
Impacto de Temporal Features:
Mejora de 8.7% en AUC (0.6625 ‚Üí 0.7204)
Las temporal features son cr√≠ticas para modelos predictivos temporales

Categor√≠as M√°s Importantes:

Lag/Window features: 28.8% de importancia total
Diversity features: 17.1% de importancia total
RFM features: 15.0% de importancia total

Top 5 Features Predictivas:

Product diversity ratio
Recency (d√≠as desde √∫ltima orden)
Unique products
Spend en √∫ltimos 90 d√≠as
Lag 3 de d√≠as entre √≥rdenes
Prevenci√≥n de Data Leakage con Pandas¬∂
Reglas de oro:

‚úÖ Siempre usar .groupby() + .shift(1) antes de aggregations temporales
‚úÖ TimeSeriesSplit para cross-validation (nunca KFold)
‚úÖ Solo forward fill (ffill), nunca backward fill (bfill)
‚úÖ Rolling temporal con .shift(1) antes de .rolling()
‚úÖ Verificar que val dates > train dates en cada fold
Sintaxis clave:

# ‚úÖ CORRECTO: Previene data leakage
feature_lag = df.groupby('user_id')['value'].shift(1)
feature_rolling = df.groupby('user_id')['value'].shift(1).rolling(window=3).mean()
feature_expanding = df.groupby('user_id')['value'].shift(1).expanding().sum()

# ‚ùå INCORRECTO: Causa data leakage
feature_lag = df['value'].shift(1)  # Sin groupby!
feature_rolling = df['value'].rolling(window=3).mean()  # Sin shift!
üîç Preguntas de Reflexi√≥n¬∂
1. ¬øQu√© window size (7d, 30d, 90d) parece m√°s importante seg√∫n feature importance?

Respuesta: Seg√∫n el an√°lisis de importancia de features, las ventanas intermedias (30d) suelen aportar m√°s se√±al que 7d (muy ruidosa) y 90d (demasiado amplia). Razonamiento: 30 d√≠as captura cambios de comportamiento reciente sin el ruido diario ni la diluci√≥n del hist√≥rico trimestral.

2. ¬øLas external variables (economic indicators) agregaron valor significativo? ¬øPor qu√© crees que s√≠ o no?

Respuesta: No aportaron un valor fuerte en este experimento. Motivos: las variables econ√≥micas fueron simuladas y mensuales (baja resoluci√≥n frente a eventos por orden), y el comportamiento de recompra est√° dominado por se√±ales de usuario (lags, RFM, ventanas). Podr√≠an ser √∫tiles en contextos con shocks macro reales o con indicadores de mayor resoluci√≥n.

3. ¬øQu√© features de RFM (Recency, Frequency, Monetary) son m√°s predictivas?

Respuesta: Recency (d√≠as desde la √∫ltima compra) es la m√°s predictiva, seguida de Frequency. Monetary (gasto medio/total) aporta algo pero con menor peso relativo. Explicaci√≥n: la probabilidad de volver a comprar est√° fuertemente ligada al tiempo desde la √∫ltima orden.

4. ¬øObservaste alguna se√±al de data leakage? ¬øC√≥mo lo detectaste?

Respuesta: No se observ√≥ evidencia clara de leakage. Comprobaciones usadas: .groupby()+.shift(1) en agregaciones, forward-fill solo, TimeSeriesSplit con validaciones posteriores a los train dates, comprobaci√≥n de gap razonable entre train score y CV AUC y revisi√≥n de top features para nombres sospechosos. Ninguna de estas comprobaciones devolvi√≥ alertas relevantes.

5. ¬øC√≥mo cambiar√≠a tu implementaci√≥n si tuvieras que deployar esto en producci√≥n y hacer predicciones diarias?

Respuesta: Principales cambios (resumen):

Mantener un feature store / estado por usuario (√∫ltima orden, lags, acumulados) actualizado en streaming o batch diario.
Calcular s√≥lo features incrementales (shifted, rolling/expanding online) para evitar costosos groupby completos.
Versionar features y modelo; exponer modelo via API (serving) con request latency baja.
Pipeline ETL diario: ingesta, actualizaci√≥n de indicadores externos (ffill), computaci√≥n incremental de ventanas, scoring.
Monitoring: drift de datos, rendimiento, alertas; backfills y retrain programado (p. ej. semanal).
Manejo de cold-start (nuevos usuarios), imputaci√≥n determin√≠stica y controles anti-leakage (siempre usar datos hist√≥ricos).
üìö Referencias y Recursos¬∂
Dataset: Online Retail Dataset (Kaggle)
Temporal Feature Engineering: Feature Engineering for Machine Learning - Cap. 7
Time Series Validation: TimeSeriesSplit (Scikit-learn)
RFM Analysis: Framework cl√°sico de an√°lisis de comportamiento en e-commerce
Pandas Temporal Operations: Pandas Time Series
‚úÖ Checklist de Implementaci√≥n¬∂
Lag features implementadas con .groupby() + .shift()
Rolling window features con .shift(1) antes de .rolling()
Expanding window features con .shift(1) antes de .expanding()
RFM features (Recency, Frequency, Monetary)
Time window aggregations (7d, 30d, 90d)
Product diversity features
Calendar features con encoding c√≠clico (sin/cos)
External variables (economic indicators)
TimeSeriesSplit validation
Comparaci√≥n con vs sin temporal features
Feature importance analysis
Data leakage detection
Visualizaciones completas
29 de octubre de 2025
Made with Material for MkDocs
‚Üë